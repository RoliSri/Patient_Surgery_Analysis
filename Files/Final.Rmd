---
title: "Patient surgery Analysis"
author: "Roli Srivastava"
date: "February 20, 2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("IRATER")
library(Matching)
library(MatchIt)
library(dplyr)
library(twang)
library(survey)
library(optmatch)
library(party)
library(rgenoud)
library(rbounds)
library(ggplot2)
library(treatSens)
library(IRATER)
library(readxl)
library(car)
library(magrittr)

```

```{r}
# factoring and scaling the cov for analysis
PatientData <- read_excel("../PatientData.xlsx") #
PatientData$severe <- factor(PatientData$severe) 
PatientData$cognitivedecline <-  factor(PatientData$cognitivedecline)
PatientData$depression <- factor(PatientData$depression)
PatientData$cancer <- factor(PatientData$cancer)
PatientData$autoimmune <- factor(PatientData$autoimmune)
PatientData$transferedin <- factor(PatientData$transferedin)
PatientData$sex <- factor(PatientData$sex)
PatientData$yearseducation <- factor(PatientData$yearseducation)
PatientData$nolifesupportorder <- factor(PatientData$nolifesupportorder)
PatientData$insurancetype <- factor(PatientData$insurancetype)
PatientData$resp <- factor(PatientData$resp)
PatientData$infection <- factor(PatientData$infection)
PatientData$trauma <- factor(PatientData$trauma)
PatientData$race <- factor(PatientData$race)
PatientData$age <- scale(PatientData$age)
PatientData$bloodpressure <- scale(PatientData$bloodpressure)
PatientData$temperature <- scale(PatientData$temperature)
PatientData$creatinelevels <- scale(PatientData$creatinelevels)
PatientData$sodiumlevels <- scale(PatientData$sodiumlevels)
PatientData$urineweight <- scale(PatientData$urineweight)
PatientData$kg <- scale(PatientData$kg)
PatientData$income <- scale(PatientData$income)
PatientData$surgerytype <- PatientData$surgerytype

#build the full model (all potential IVs to see if they predict assignment):
psmodel <- glm(surgerytype ~ age + bloodpressure + temperature + creatinelevels + sodiumlevels + urineweight  + kg + income +  severe + cognitivedecline + depression + cancer + autoimmune + transferedin + sex + yearseducation + nolifesupportorder + insurancetype +  resp + infection + trauma + race , data = PatientData, family = 'binomial')

summary(psmodel)

#Reduced model based on the covariates which are significant
psmodelfinal <- glm(surgerytype ~ bloodpressure + creatinelevels + sodiumlevels + urineweight  + kg + severe + 
                  cognitivedecline + depression + cancer + transferedin + nolifesupportorder + insurancetype +  resp 
                + infection + trauma, data = PatientData, family = "binomial")

summary(psmodelfinal)

vif(psmodelfinal)
#no mulitcollinearity is found.

#Lets make our data frame excluding any NA and missing data.
dataready <- na.omit(PatientData)
psf <- formula('surgerytype ~ bloodpressure + creatinelevels + sodiumlevels + urineweight  + kg + severe + 
                  cognitivedecline + depression + cancer + transferedin + nolifesupportorder + insurancetype +  resp 
                + infection + trauma')

#Let's get our PS generated by Logit:
logit <- glm(psf, family = "binomial", data = dataready)
dataready$ps <- fitted(logit)

#Plotting the data we get the overlap which looks good . It does look like we have quite a bit of common support:
dataready %>%
ggplot(aes(x = ps)) +
geom_histogram(color = "white") +
facet_wrap(~surgerytype) 

#Lets try at least one other method (recursive partitioning with 5000 trees):
#controls <- cforest_unbiased(ntree = 1000, mtry = 2)
#forest <- cforest(psf, data = as.data.frame(dataready), controls = controls)
#forestfit <- predict(forest, type="prob")
#dataready$fps <- matrix(unlist(forestfit),,2,byrow=T)[,2]

##error in cforest data so trying gbm - Generalized Boosting Model

gbm <- ps(psf, data = as.data.frame(dataready), n.trees = 3000, stop.method=c("es.max"), verbose = TRUE)
dataready$gmbfit <- gbm$ps

dataready %>%
ggplot(aes(x = dataready$gmbfit$es.max.ATE)) +
geom_histogram(color = "white") +
facet_wrap(~surgerytype)

#due to error cforest is aborted , so tried gbm where overlap looks worse than logit so we will use logit score so  Lets stick with the first model using standard regression estimation of PS (dataready$ps). 

dataready$logps <- log(dataready$ps/(1- dataready$ps))

#________________________________________Stratified______________________________________________________________________

#Will go with the method provided in the matchit ,lets go with 5 stratum.
stratified <- matchit(psf, data = dataready, distance = dataready$logps, method = "subclass", sub.by = "treat", subclass = 5)
stratified
stratumworking <- match.data(stratified)


#Lets look at the standard mean difference to see how well we balanced this data:
check <- summary(stratified, standardize = TRUE)
stdmeandifferences <- data.frame(check$q.table[,3,])
summary(stdmeandifferences)


#We are above our .1 strict cut off for some but mostly below our .25 cutoff. 

design <- svydesign(id = ~0, data = stratumworking)
ntreat <- data.frame(table(stratumworking$subclass[stratumworking$surgerytype == 1]))
names(ntreat) <- c("subclass", "N.1s")
ncontrol <- data.frame(table(stratumworking$subclass[stratumworking$surgerytype == 0]))
names(ncontrol) <- c("subclass", "N.0s")
scounts <- merge(ntreat, ncontrol)
stratumworking <- merge(stratumworking, scounts)
propt <- svymean(~factor(surgerytype), design)

stratumworking$weights <- with(stratumworking, ifelse(surgerytype == 1, 1, stratumworking$N.1s*propt[1]/ stratumworking$N.0s*propt[2]))
xtabs(~weights  +subclass, stratumworking)
stratumworking$ATTwFinal  <- stratumworking$weights /mean(stratumworking$weights)


bal.stat(stratumworking, estimand = "ATT", w.all = stratumworking$ATTwFinal, vars = cbind('bloodpressure' , 'creatinelevels' , 'sodiumlevels' , 'urineweight'  , 'kg', 'severe' , 'cognitivedecline' , 'depression' , 'cancer' , 'transferedin' , 'nolifesupportorder' , 'insurancetype' ,  'resp' , 'infection' , 'trauma'), sampw = 1, get.ks = FALSE,  treat.var = "surgerytype", multinom = FALSE)$results


#balance For bloodpressure , kg and nolifesupportorder  and infection it is not good and it's significant

stratumworking$died <- scale(stratumworking$died)
#balance looks perfect lets do an analysis with bootstrapping:
design <- svydesign(ids = ~0, weights = stratumworking$ATTwFinal, data = stratumworking)
design <- as.svrepdesign(design, type = c("bootstrap"), replicates = 5000)

model <- svyglm(died ~ factor(surgerytype) + age + bloodpressure + temperature + creatinelevels + sodiumlevels + urineweight  + kg + severe + cognitivedecline + depression + cancer + transferedin + nolifesupportorder + insurancetype +  resp + infection + trauma , design = design, family = gaussian())

summary(model)

#surgerytype appears to have a significant impact with surgerytype 1 leading to a .06 SD increase in deat. Lets see how susceptible we are to bias:
#many covariates also seem to impact

sensitivity <- treatSens(died ~ factor(surgerytype) + ps + I((ps)^2) + I((ps)^3), trt.family = binomial(link = "probit"), grid.dim = c(5,5), nsim = 20, weights = stratumworking$AttwFinal, data = stratumworking)
#Coefficients on U where tau = 0:
summary(sensitivity)
sensPlot(sensitivity) 

#It looks unlikely that the size of the effect is not truly 0, but it does appear that it’s a very strong effect (our analysis finds it significant and many impact lurking covariates). 

```

```{r}
#____________________________________Weighting__________________________________________________________________________
#Lets now turn to weighting and see if it returns more robust or even different results. Note we use the raw ps here as log corrected will result in negative weights which aren’t possible.

dataready$ATTw <- with(dataready, ifelse(surgerytype == 1, 1, ps/(1-ps)))
with(dataready, by(ATTw, surgerytype, summary))

dataready$correctedweights <- with(dataready, ifelse(surgerytype == 1, mean(ps)/ps, mean(1-ps)/(1-ps)))
with(dataready, by(correctedweights, surgerytype, summary))

#It looks like the corrected weights are not bringing about better balance:
model1 <- glm (age ~ surgerytype, weights = ATTw, data = dataready)
summary(model1)
model2 <- glm (cancer ~ surgerytype, weights = ATTw, data = dataready, family = "quasibinomial")
summary(model2)
model3 <- glm (age ~ surgerytype, weights = correctedweights, data = dataready)
summary(model3)
model4 <- glm (cancer ~ surgerytype, weights = correctedweights, data = dataready, family = "quasibinomial")
summary(model4)

#Now we can see what the effect is:
dataready$died <- scale(dataready$died)

design <- svydesign(ids = ~0, weights = dataready$correctedweights, data = dataready)
design <- as.svrepdesign(design, type = c("bootstrap"), replicates = 5000)


model <- svyglm(died ~ factor(surgerytype) + age + bloodpressure + temperature + creatinelevels + sodiumlevels + urineweight  + kg + severe + cognitivedecline + depression + cancer + transferedin + nolifesupportorder + insurancetype +  resp + infection + trauma, design = design, family = gaussian())
summary(model)

finalmodelWt <- svyglm(died ~ factor(surgerytype) + bloodpressure + temperature + creatinelevels + kg +  cognitivedecline + cancer + transferedin + nolifesupportorder + trauma, design = design, family = gaussian())
summary(finalmodelWt)

sensitivity <- treatSens(died ~ factor(surgerytype) + ps + I((ps)^2) + I((ps)^3), trt.family = binomial(link = "probit"), grid.dim = c(5,5), nsim = 20, weights = dataready$correctedweights, data = dataready)
summary(sensitivity)
sensPlot(sensitivity)

#The results are about the same but with weighting. 
```


```{r}
##__________________________________Matching_______________________________________________________________________
#Greedy Matching
greedy <- matchit(psf, distance = dataready$logps, m.order = "largest", data = dataready, method = "nearest", replace = TRUE, caliper = .25)
summary(greedy)

#Genetic Matching was taking very long time so leaving it for now- using pop.size as 100 due to time constraint , ideally it should be 1000 or more for larger sample
#genetic <- matchit(psf, distance = dataready$logps, data = dataready, method = 'genetic', pop.size = 100, fit.func='pvals', estimand = 'ATT', replace = TRUE, ties = TRUE)
#summary(genetic)

#Optimal Matching
optimal <- matchit(psf, distance = dataready$logps, data = as.data.frame(dataready), method = 'optimal', ratio = 1)
summary(optimal)

# so optimal is matching better so will go by optimal matching
#Analysis
readydata <- match.data(optimal)
analysis <- svydesign(ids = ~1, weights = ~weights, data = readydata)

model <- svyglm(died ~  factor(surgerytype), analysis, family = gaussian())

summary(model)

model2 <- svyglm(died ~ factor(surgerytype) + age + bloodpressure + temperature + creatinelevels + sodiumlevels + urineweight  + kg + severe + cognitivedecline + depression + cancer + transferedin + nolifesupportorder + insurancetype +  resp + infection + trauma, analysis, family = gaussian())

summary(model2)


```